{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from geopy.geocoders import Nominatim\n",
    "from elasticsearch import Elasticsearch\n",
    "import spacy\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    [{'host': 'localhost', 'port': 9200, 'scheme': 'http'}],http_auth=('osama', 'osama123'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_mapping = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"title_analyzer\",\n",
    "                \"search_analyzer\": \"standard\"\n",
    "            },\n",
    "            'content': {\n",
    "                'type': 'text',\n",
    "                'analyzer': 'content_analyzer'\n",
    "            },\n",
    "            \"authors\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"first_name\": {\"type\": \"text\"},\n",
    "                    \"last_name\": {\"type\": \"text\"}\n",
    "                }\n",
    "            },\n",
    "            \"date\": {\n",
    "                \"type\": \"date\"\n",
    "            },\n",
    "            \"geopoint\": {\"type\": \"geo_point\"},\n",
    "            \"temporal_expressions\": {\"type\": \"text\"},\n",
    "            \"georeferences\": {\"type\": \"text\"}\n",
    "        },\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"title_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"autocomplete_tokenizer\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                },\n",
    "                \"content_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"char_filter\": [\"html_strip\"],\n",
    "                    \"filter\": [\"lowercase\", \"stop\", \"length\", \"porter_stem\"]\n",
    "                }\n",
    "            },\n",
    "            \"tokenizer\": {\n",
    "                \"autocomplete_tokenizer\": {\n",
    "                    \"type\": \"edge_ngram\",\n",
    "                    \"min_gram\": 2,\n",
    "                    \"max_gram\": 10,\n",
    "                    \"token_chars\": [\"letter\", \"digit\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"reuter_news_index\"\n",
    "es.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a geocoder instance\n",
    "geolocator = Nominatim(user_agent=\"geo_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_date(reuters_tag):\n",
    "    date_tag = reuters_tag.find('date')\n",
    "    \n",
    "    if date_tag:\n",
    "        date_text = date_tag.get_text() \n",
    "        # Adjust the format string to match the actual format of your date string\n",
    "        parsed_date = datetime.strptime(date_text, \"%d-%b-%Y %H:%M:%S.%f\")\n",
    "        # Format the datetime object as a string compatible with Elasticsearch date fields\n",
    "        elasticsearch_date = parsed_date.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "        return elasticsearch_date\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors(reuters_tag):\n",
    "    author_tag = reuters_tag.find('author')\n",
    "    \n",
    "    if author_tag:\n",
    "        author_text = author_tag.get_text().strip()\n",
    "        names = author_text.split(' ')\n",
    "        \n",
    "        # Assuming the first name is the first element and the last name is the last element\n",
    "        if len(names) >= 2:\n",
    "            first_name = names[0]\n",
    "            last_name = names[-1]\n",
    "            return (first_name, last_name)\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_title(reuters_tag):\n",
    "    title_tag = reuters_tag.find('title')\n",
    "    return title_tag.get_text() if title_tag else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(reuters_tag):\n",
    "    text_tag = reuters_tag.find('text')\n",
    "    return text_tag.get_text() if text_tag else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_georeferences(reuters_tag):\n",
    "    places_tag = reuters_tag.find('places')\n",
    "    return [place.get_text() for place in places_tag.find_all('d')] if places_tag else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_temporal_expressions(text):\n",
    "    doc = nlp(text)\n",
    "    return [ent.text for ent in doc.ents if ent.label_ == 'DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_geopoints(georeferences):\n",
    "    geolocator = Nominatim(user_agent=\"geo_app\")\n",
    "    geopoints = []\n",
    "    \n",
    "    for place_name in georeferences:\n",
    "        location = geolocator.geocode(place_name)\n",
    "        if location:\n",
    "            geopoints.append({'latitude': location.latitude, 'longitude': location.longitude})\n",
    "    return geopoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_document(title, content, authors, date, geopoints, temporal_expressions, georeferences):\n",
    "    try:\n",
    "        # Ensure that required fields have valid values before indexing\n",
    "        if title and content and geopoints:\n",
    "            document = {\n",
    "                'title': title,\n",
    "                'content': content,\n",
    "                'date': date,\n",
    "                'geopoint': [{'lat': point['latitude'], 'lon': point['longitude']} for point in geopoints],\n",
    "                'temporalExpressions': temporal_expressions,\n",
    "                'georeferences': georeferences\n",
    "            }\n",
    "\n",
    "            # Include authors field only if authors is not None\n",
    "            if authors is not None:\n",
    "                document['authors'] = authors\n",
    "\n",
    "            # Index the document\n",
    "            es.index(index='reuter_news_index', body=document)\n",
    "            print(f\"Document indexed successfully: {title}\")\n",
    "        else:\n",
    "            print(\"Skipping document due to missing required fields.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error indexing document: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gsm_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    reuters_tags = soup.find_all('reuters')\n",
    "    \n",
    "    for reuters_tag in reuters_tags:\n",
    "        date = extract_date(reuters_tag)\n",
    "        authors = extract_authors(reuters_tag)\n",
    "        title = extract_article_title(reuters_tag)\n",
    "        file_content = extract_content(reuters_tag)\n",
    "        georeferences = extract_georeferences(reuters_tag)\n",
    "        temporal_expressions = extract_temporal_expressions(file_content)\n",
    "        \n",
    "        if georeferences:\n",
    "            geopoints = extract_geopoints(georeferences)\n",
    "        else:\n",
    "            geopoints = None\n",
    "        \n",
    "        # Check if authors is not None before indexing\n",
    "        if authors is not None:\n",
    "            # Unpack the authors tuple and pass it to the index_document function\n",
    "            index_document(title, file_content, authors, date, geopoints, temporal_expressions, georeferences)\n",
    "        else:\n",
    "            # Handle the case where authors is None (provide default values or skip indexing)\n",
    "            print(\"Skipping document due to missing authors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sgm_folder(folder_path):\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".sgm\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            read_gsm_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "data_folder = \"./data/\"\n",
    "process_sgm_folder(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
